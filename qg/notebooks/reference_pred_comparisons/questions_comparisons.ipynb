{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DeboraOrsolich\\miniconda3\\envs\\ques_gen_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-08-14 15:11:55,191 - C:\\Users\\DeboraOrsolich\\Development\\question_generation_models\\deep_qg\\qg\\config\\config.py\n",
      "    INFO -\n",
      "        function: <module>@54\n",
      "        Day: 2022-08-14, time: 1660486315.1901588, running in device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import notebook_hook\n",
    "import pathlib\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from qg.results_analysis.objects.POSAnalysis import POS_analysis_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory: C:\\Users\\DeboraOrsolich\\Development\\question_generation_models\\deep_qg\\qg\n"
     ]
    }
   ],
   "source": [
    "PACKAGE_ROOT = pathlib.Path().resolve().parents[1]\n",
    "print(f\"Root directory: {PACKAGE_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating NLP pipeline with 'predictions AA' questions...\n",
      "Pipeline generated. Extracting concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18836/18836 [00:00<00:00, 57610.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts from AA_train_predictions extracted.\n",
      "Generating NLP pipeline with 'references AA' questions...\n",
      "Pipeline generated. Extracting concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18836/18836 [00:00<00:00, 79380.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts from AA_train_references extracted.\n",
      "Generating NLP pipeline with 'predictions AQPL' questions...\n",
      "Pipeline generated. Extracting concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21890/21890 [00:00<00:00, 71396.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts from AQPL_train_predictions extracted.\n",
      "Generating NLP pipeline with 'references AQPL' questions...\n",
      "Pipeline generated. Extracting concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21890/21890 [00:00<00:00, 77255.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts from AQPL_train_references extracted.\n",
      "Generating NLP pipeline with 'predictions basic' questions...\n",
      "Pipeline generated. Extracting concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18836/18836 [00:00<00:00, 44803.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts from basic_train_predictions extracted.\n",
      "Generating NLP pipeline with 'references basic' questions...\n",
      "Pipeline generated. Extracting concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18836/18836 [00:00<00:00, 43485.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts from basic_train_references extracted.\n",
      "Generating NLP pipeline with 'predictions OQPL' questions...\n",
      "Pipeline generated. Extracting concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18836/18836 [00:00<00:00, 41898.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts from OQPL_train_predictions extracted.\n",
      "Generating NLP pipeline with 'references OQPL' questions...\n",
      "Pipeline generated. Extracting concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18836/18836 [00:00<00:00, 39330.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts from OQPL_train_references extracted.\n",
      "Generating NLP pipeline with 'predictions AA' questions...\n",
      "Pipeline generated. Extracting concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [00:00<00:00, 90077.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts from AA_validation_predictions extracted.\n",
      "Generating NLP pipeline with 'references AA' questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline generated. Extracting concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [00:00<00:00, 81091.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts from AA_validation_references extracted.\n",
      "Generating NLP pipeline with 'predictions AQPL' questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline generated. Extracting concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [00:00<00:00, 74046.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts from AQPL_validation_predictions extracted.\n",
      "Generating NLP pipeline with 'references AQPL' questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline generated. Extracting concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [00:00<00:00, 80135.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts from AQPL_validation_references extracted.\n",
      "Generating NLP pipeline with 'predictions basic' questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline generated. Extracting concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [00:00<00:00, 83315.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts from basic_validation_predictions extracted.\n",
      "Generating NLP pipeline with 'references basic' questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline generated. Extracting concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [00:00<00:00, 79025.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts from basic_validation_references extracted.\n",
      "Generating NLP pipeline with 'predictions OQPL' questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline generated. Extracting concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [00:00<00:00, 70888.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts from OQPL_validation_predictions extracted.\n",
      "Generating NLP pipeline with 'references OQPL' questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline generated. Extracting concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [00:00<00:00, 78283.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts from OQPL_validation_references extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR_AA = PACKAGE_ROOT/'qg'/'transformers_models'/'experiment_AA'\n",
    "DATA_DIR_AQPL = PACKAGE_ROOT/'qg'/'transformers_models'/'experiment_AQPL'\n",
    "DATA_DIR_BASIC = PACKAGE_ROOT/'qg'/'transformers_models'/'experiment_basic'\n",
    "DATA_DIR_OQPL = PACKAGE_ROOT/'qg'/'transformers_models'/'experiment_OQPL'\n",
    "\n",
    "results_folders = [\"AA\", \"AQPL\", \"basic\", \"OQPL\"]\n",
    "splits = [\"train\", \"validation\"]\n",
    "pos_results = {}\n",
    "\n",
    "for split in splits:\n",
    "    for folder in results_folders:\n",
    "\n",
    "        # Uploading generated questions...\n",
    "        with open(PACKAGE_ROOT/f\"transformers_models/experiment_{folder}/mapped_{split}_questions.json\", encoding=\"utf-8\") as f:\n",
    "            questions = json.load(f)\n",
    "            predictions = questions[\"predictions\"]\n",
    "            references = questions[\"references\"]\n",
    "\n",
    "            sets = [predictions, references]\n",
    "            sets_names = [\"predictions\", \"references\"]\n",
    "\n",
    "            for s_i,(set_, name) in enumerate(zip(sets, sets_names)):\n",
    "\n",
    "                print(f\"Generating NLP pipeline with '{name} {folder}' questions...\")\n",
    "                pos_analysis = POS_analysis_object()\n",
    "                questions_pipeline = pos_analysis.nlp_pipeline(set_)\n",
    "\n",
    "                print(f\"Pipeline generated. Extracting concepts...\")\n",
    "                strings = []\n",
    "                lemmas = []\n",
    "\n",
    "                for question in tqdm(questions_pipeline):\n",
    "                    pos_analysis.extract_pos_concepts(question, split_in_documents=True)\n",
    "                    strings.append(pos_analysis.all_concepts_string)\n",
    "                    lemmas.append(pos_analysis.all_concepts_lemma)\n",
    "\n",
    "                concepts = {}\n",
    "                concepts[\"strings\"] = strings\n",
    "                concepts[\"lemmas\"]  = lemmas\n",
    "                pos_results[f\"{folder}_{split}_{name}\"] = concepts\n",
    "            \n",
    "                print(f\"Concepts from {folder}_{split}_{name} extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AA_train_predictions', 'AA_train_references', 'AQPL_train_predictions', 'AQPL_train_references', 'basic_train_predictions', 'basic_train_references', 'OQPL_train_predictions', 'OQPL_train_references', 'AA_validation_predictions', 'AA_validation_references', 'AQPL_validation_predictions', 'AQPL_validation_references', 'basic_validation_predictions', 'basic_validation_references', 'OQPL_validation_predictions', 'OQPL_validation_references'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(list1:list, list2:list):\n",
    "    return list(set(list1) & set(list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********* EXPERIMENT: AA ***********\n",
      "Train set...\n",
      "   There are a total of 18836 questions\n",
      "   There are not concepts in common between ref and pred in 7761 questions, (the 0.41203015502229773%)\n",
      "   There are concepts in common between ref and pred in 11075 questions, (the 0.5879698449777023%)\n",
      "\n",
      "Validation set...\n",
      "   There are a total of 1177 questions in the validation set\n",
      "   There are not concepts in common between ref and pred in 507 questions, (the 0.43075615972812237%)\n",
      "   There are concepts in common between ref and pred in 670 questions, (the 0.5692438402718777%)\n",
      "Train set...\n",
      "  Ref average length: 61.09503079210023      Ref length std 20.840692414976075\n",
      "  Pref average length: 58.38421108515608    Ref length std 19.885628682390237\n",
      "\n",
      "Validation set...\n",
      "  Ref average length: 62.43160577740017      Ref length std 21.841375004275342\n",
      "  Pref average length: 59.81988105352591    Ref length std 21.05980912932479\n",
      "\n",
      "\n",
      "********* EXPERIMENT: AQPL ***********\n",
      "Train set...\n",
      "   There are a total of 21890 questions\n",
      "   There are not concepts in common between ref and pred in 8616 questions, (the 0.39360438556418453%)\n",
      "   There are concepts in common between ref and pred in 13274 questions, (the 0.6063956144358155%)\n",
      "\n",
      "Validation set...\n",
      "   There are a total of 1350 questions in the validation set\n",
      "   There are not concepts in common between ref and pred in 484 questions, (the 0.3585185185185185%)\n",
      "   There are concepts in common between ref and pred in 866 questions, (the 0.6414814814814814%)\n",
      "Train set...\n",
      "  Ref average length: 61.42160804020101      Ref length std 20.90974533440355\n",
      "  Pref average length: 69.07619917770671    Ref length std 30.559245232066306\n",
      "\n",
      "Validation set...\n",
      "  Ref average length: 63.178518518518516      Ref length std 20.816624002038605\n",
      "  Pref average length: 70.98962962962963    Ref length std 32.02431778340415\n",
      "\n",
      "\n",
      "********* EXPERIMENT: basic ***********\n",
      "Train set...\n",
      "   There are a total of 18836 questions\n",
      "   There are not concepts in common between ref and pred in 7161 questions, (the 0.3801762582289233%)\n",
      "   There are concepts in common between ref and pred in 11675 questions, (the 0.6198237417710767%)\n",
      "\n",
      "Validation set...\n",
      "   There are a total of 1177 questions in the validation set\n",
      "   There are not concepts in common between ref and pred in 446 questions, (the 0.37892948173322005%)\n",
      "   There are concepts in common between ref and pred in 731 questions, (the 0.62107051826678%)\n",
      "Train set...\n",
      "  Ref average length: 60.22802081121257      Ref length std 20.59212869023792\n",
      "  Pref average length: 58.590730516033126    Ref length std 22.472434143266025\n",
      "\n",
      "Validation set...\n",
      "  Ref average length: 61.62701784197111      Ref length std 21.53894855536221\n",
      "  Pref average length: 59.92353440951572    Ref length std 23.520072558697667\n",
      "\n",
      "\n",
      "********* EXPERIMENT: OQPL ***********\n",
      "Train set...\n",
      "   There are a total of 18836 questions\n",
      "   There are not concepts in common between ref and pred in 8729 questions, (the 0.4634211085156084%)\n",
      "   There are concepts in common between ref and pred in 10107 questions, (the 0.5365788914843916%)\n",
      "\n",
      "Validation set...\n",
      "   There are a total of 1177 questions in the validation set\n",
      "   There are not concepts in common between ref and pred in 483 questions, (the 0.4103653355989805%)\n",
      "   There are concepts in common between ref and pred in 694 questions, (the 0.5896346644010195%)\n",
      "Train set...\n",
      "  Ref average length: 63.55563813973243      Ref length std 21.237803879257413\n",
      "  Pref average length: 68.70784667657676    Ref length std 28.07130297217041\n",
      "\n",
      "Validation set...\n",
      "  Ref average length: 65.1928632115548      Ref length std 21.92338594652337\n",
      "  Pref average length: 69.26338147833475    Ref length std 27.96153371446226\n"
     ]
    }
   ],
   "source": [
    "for folder in results_folders:\n",
    "    print()\n",
    "    print()\n",
    "    print(f\"********* EXPERIMENT: {folder} ***********\")\n",
    "\n",
    "    with open(PACKAGE_ROOT/f\"transformers_models/experiment_{folder}/mapped_train_questions.json\", encoding=\"utf-8\") as f:\n",
    "        questions_train = json.load(f)\n",
    "    with open(PACKAGE_ROOT/f\"transformers_models/experiment_{folder}/mapped_validation_questions.json\", encoding=\"utf-8\") as f:\n",
    "        questions_val = json.load(f)\n",
    "    \n",
    "\n",
    "    intersections = {}\n",
    "    intersections[\"train\"] = []\n",
    "    for (ref, pred) in zip(pos_results[f\"{folder}_train_references\"][\"lemmas\"], pos_results[f\"{folder}_train_predictions\"][\"lemmas\"]):\n",
    "        intersections[\"train\"].append(intersection(ref, pred))\n",
    "\n",
    "    intersections[\"validation\"] = []\n",
    "    for (ref, pred) in zip(pos_results[f\"{folder}_validation_references\"][\"lemmas\"], pos_results[f\"{folder}_validation_predictions\"][\"lemmas\"]):\n",
    "        intersections[\"validation\"].append(intersection(ref, pred))\n",
    "\n",
    "    print(\"Train set...\")\n",
    "    print(f\"   There are a total of {len(intersections['train'])} questions\")\n",
    "    print(f\"   There are not concepts in common between ref and pred in {intersections['train'].count([])} questions, (the {intersections['train'].count([])/len(intersections['train'])}%)\")\n",
    "    print(f\"   There are concepts in common between ref and pred in {len(intersections['train']) - intersections['train'].count([])} questions, (the {(len(intersections['train']) - intersections['train'].count([]))/len(intersections['train'])}%)\")\n",
    "\n",
    "\n",
    "    print()\n",
    "    print(\"Validation set...\")\n",
    "    print(f\"   There are a total of {len(intersections['validation'])} questions in the validation set\")\n",
    "    print(f\"   There are not concepts in common between ref and pred in {intersections['validation'].count([])} questions, (the {intersections['validation'].count([])/len(intersections['validation'])}%)\")\n",
    "    print(f\"   There are concepts in common between ref and pred in {len(intersections['validation']) - intersections['validation'].count([])} questions, (the {(len(intersections['validation']) - intersections['validation'].count([]))/len(intersections['validation'])}%)\")\n",
    "\n",
    "    train_ref_lengths = [len(question) for question in questions_train[\"references\"]]\n",
    "    train_pred_lengths = [len(question) for question in questions_train[\"predictions\"]]\n",
    "\n",
    "    val_ref_lengths = [len(question) for question in questions_val[\"references\"]]\n",
    "    val_pred_lengths = [len(question) for question in questions_val[\"predictions\"]]\n",
    "\n",
    "    print(\"Train set...\")\n",
    "    print(f\"  Ref average length: {np.mean(train_ref_lengths)}      Ref length std {np.std(train_ref_lengths)}\")\n",
    "    print(f\"  Pref average length: {np.mean(train_pred_lengths)}    Ref length std {np.std(train_pred_lengths)}\")\n",
    "\n",
    "\n",
    "    print()\n",
    "    print(\"Validation set...\")\n",
    "    print(f\"  Ref average length: {np.mean(val_ref_lengths)}      Ref length std {np.std(val_ref_lengths)}\")\n",
    "    print(f\"  Pref average length: {np.mean(val_pred_lengths)}    Ref length std {np.std(val_pred_lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ques_gen_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc601a73fdd21029cabb389f5777df311758dfa951f719b3a4a78b5169f7a217"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
